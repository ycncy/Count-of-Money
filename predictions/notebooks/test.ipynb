{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from predictions.pipeline.enum.time_interval import TimeInterval\n",
    "\n",
    "\n",
    "class DataCollector:\n",
    "    def __init__(self, coin_id: int, coin_symbol: str, currency: str = \"USD\",\n",
    "                 interval: TimeInterval = TimeInterval.DAY):\n",
    "        self.ticker = None\n",
    "        self.coin_id = coin_id\n",
    "        self.coin_symbol = coin_symbol\n",
    "        self.currency = currency\n",
    "        self.interval = interval\n",
    "\n",
    "    def _get_ticker(self):\n",
    "        ticker_symbol = f\"{self.coin_symbol}-{self.currency}\"\n",
    "        self.ticker = yf.Ticker(ticker_symbol)\n",
    "\n",
    "    def _collect_data_other_intervals(self, interval) -> dict:\n",
    "        period_mapping = {\n",
    "            \"1m\": \"7d\",\n",
    "            \"1h\": \"730d\",\n",
    "            \"1d\": \"7y\",\n",
    "            \"5d\": \"7y\",\n",
    "            \"1w\": \"7y\",\n",
    "            \"1mo\": \"7y\",\n",
    "        }\n",
    "\n",
    "        period = period_mapping.get(interval.value, \"7d\")\n",
    "        data = self.ticker.history(period=period, interval=interval.value)\n",
    "\n",
    "        return data.to_dict()\n",
    "\n",
    "    def _process_and_save_data(self, raw_data_from_api: dict):\n",
    "        processed_data = pd.DataFrame(raw_data_from_api).drop([\"Dividends\", \"Stock Splits\"], axis=1)\n",
    "\n",
    "        processed_data = processed_data.reset_index().rename(columns={'index': 'datetime'})\n",
    "\n",
    "        directory_path = f\"../data/processed_data/{self.coin_symbol}/{self.interval.name}\"\n",
    "\n",
    "        if not os.path.exists(directory_path):\n",
    "            os.makedirs(directory_path)\n",
    "\n",
    "        timestamp_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "        csv_file_path = os.path.join(directory_path, f\"{self.coin_symbol}_data_{timestamp_str}.csv\")\n",
    "\n",
    "        processed_data.to_csv(\n",
    "            path_or_buf=csv_file_path,\n",
    "            date_format=\"%Y-%m-%d %H:%M:%S\",\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "    def process_pipeline(self):\n",
    "        try:\n",
    "            self._get_ticker()\n",
    "\n",
    "            raw_data_from_api = self._collect_data_other_intervals(self.interval)\n",
    "\n",
    "            self._process_and_save_data(raw_data_from_api)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error collecting data: {e}\")\n",
    "            return None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c31db80c6379144"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "collector = DataCollector(1, \"ETH\", currency=\"USD\", interval=TimeInterval.DAY)\n",
    "data = collector.process_pipeline()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69de04ffe167e8cf"
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataframe = pd.read_csv(\"../data/processed_data/ETH/DAY/ETH_data_2023-11-21_12-14-48.csv\")\n",
    "\n",
    "# prediction_dataframe = dataframe.shift(-1).dropna()\n",
    "# prediction_dataframe = prediction_dataframe.rename(columns={\n",
    "#     \"Open\": \"Next_Open\",\n",
    "#     \"High\": \"Next_High\", \n",
    "#     \"Low\": \"Next_Low\", \n",
    "#     \"Close\": \"Next_Close\", \n",
    "#     \"Volume\": \"Next_Volume\"\n",
    "# })\n",
    "# \n",
    "# dataframe = dataframe.merge(prediction_dataframe)\n",
    "\n",
    "dataframe = dataframe.set_index(\"datetime\")\n",
    "\n",
    "dataframe = dataframe[:-20]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataframe_normalized = scaler.fit_transform(dataframe)\n",
    "\n",
    "dataframe_normalized = pd.DataFrame(dataframe_normalized, columns=dataframe.columns)\n",
    "\n",
    "sequence_length = 10\n",
    "sequences = []\n",
    "\n",
    "for i in range(len(dataframe_normalized) - sequence_length):\n",
    "    sequence = dataframe_normalized.iloc[i:i + sequence_length, :]\n",
    "    target = dataframe_normalized.iloc[i + sequence_length, :]\n",
    "    sequences.append((sequence.values, target.values))\n",
    "\n",
    "X = np.array([seq[0] for seq in sequences])\n",
    "y = np.array([seq[1] for seq in sequences])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# X_train = X_train.reshape((X_train.shape[0], sequence_length, dataframe.shape[1]))\n",
    "# X_test = X_test.reshape((X_test.shape[0], sequence_length, dataframe.shape[1]))\n",
    "\n",
    "# \n",
    "# dataframe_normalized"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T14:46:29.367709600Z",
     "start_time": "2023-11-21T14:46:29.013093900Z"
    }
   },
   "id": "26d8e6db2c1c8016"
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "data": {
      "text/plain": "2.130989195847784e+19"
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv(\"../data/processed_data/ETH/DAY/ETH_data_2023-11-21_12-14-48.csv\")\n",
    "\n",
    "df = df.set_index(\"datetime\")\n",
    "\n",
    "df = df[:-20]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "sequence_length = 10 \n",
    "data_sequences = []\n",
    "target_values = []\n",
    "\n",
    "for i in range(len(scaled_data) - sequence_length):\n",
    "    data_sequences.append(scaled_data[i:i + sequence_length])\n",
    "    target_values.append(scaled_data[i + sequence_length])\n",
    "\n",
    "data_sequences = np.array(data_sequences)\n",
    "target_values = np.array(target_values)\n",
    "\n",
    "train_size = int(len(data_sequences) * 0.8)\n",
    "train_data, test_data = data_sequences[:train_size], data_sequences[train_size:]\n",
    "train_targets, test_targets = target_values[:train_size], target_values[train_size:]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_data.reshape(-1, sequence_length * df.shape[1]), train_targets)\n",
    "\n",
    "predictions = model.predict(test_data.reshape(-1, sequence_length * df.shape[1]))\n",
    "\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "mean_squared_error(test_targets, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T15:14:46.119098900Z",
     "start_time": "2023-11-21T15:14:46.076310700Z"
    }
   },
   "id": "684bd643d4b18762"
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "data": {
      "text/plain": "                            Open         High          Low        Close  \\\n2017-11-09 00:00:00   308.644989   329.451996   307.056000   320.884003   \n2017-11-10 00:00:00   320.670990   324.717987   294.541992   299.252991   \n2017-11-11 00:00:00   298.585999   319.453003   298.191986   314.681000   \n2017-11-12 00:00:00   314.690002   319.153015   298.513000   307.907990   \n2017-11-13 00:00:00   307.024994   328.415009   307.024994   316.716003   \n...                          ...          ...          ...          ...   \n2025-01-05 00:00:00  1759.352295  1824.956299  1709.441406  1756.085693   \n2025-01-06 00:00:00  1755.309692  1821.239380  1697.009644  1737.948730   \n2025-01-07 00:00:00  1763.142334  1828.231812  1700.270020  1737.885742   \n2025-01-08 00:00:00  1781.604248  1845.217529  1721.257446  1759.425293   \n2025-01-09 00:00:00  1790.498047  1851.689575  1725.914917  1763.695190   \n\n                           Volume  \n2017-11-09 00:00:00  8.932500e+08  \n2017-11-10 00:00:00  8.859860e+08  \n2017-11-11 00:00:00  8.423010e+08  \n2017-11-12 00:00:00  1.613480e+09  \n2017-11-13 00:00:00  1.041890e+09  \n...                           ...  \n2025-01-05 00:00:00  1.136955e+10  \n2025-01-06 00:00:00  9.937840e+09  \n2025-01-07 00:00:00  9.520869e+09  \n2025-01-08 00:00:00  1.039972e+10  \n2025-01-09 00:00:00  1.004115e+10  \n\n[2619 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-11-09 00:00:00</th>\n      <td>308.644989</td>\n      <td>329.451996</td>\n      <td>307.056000</td>\n      <td>320.884003</td>\n      <td>8.932500e+08</td>\n    </tr>\n    <tr>\n      <th>2017-11-10 00:00:00</th>\n      <td>320.670990</td>\n      <td>324.717987</td>\n      <td>294.541992</td>\n      <td>299.252991</td>\n      <td>8.859860e+08</td>\n    </tr>\n    <tr>\n      <th>2017-11-11 00:00:00</th>\n      <td>298.585999</td>\n      <td>319.453003</td>\n      <td>298.191986</td>\n      <td>314.681000</td>\n      <td>8.423010e+08</td>\n    </tr>\n    <tr>\n      <th>2017-11-12 00:00:00</th>\n      <td>314.690002</td>\n      <td>319.153015</td>\n      <td>298.513000</td>\n      <td>307.907990</td>\n      <td>1.613480e+09</td>\n    </tr>\n    <tr>\n      <th>2017-11-13 00:00:00</th>\n      <td>307.024994</td>\n      <td>328.415009</td>\n      <td>307.024994</td>\n      <td>316.716003</td>\n      <td>1.041890e+09</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2025-01-05 00:00:00</th>\n      <td>1759.352295</td>\n      <td>1824.956299</td>\n      <td>1709.441406</td>\n      <td>1756.085693</td>\n      <td>1.136955e+10</td>\n    </tr>\n    <tr>\n      <th>2025-01-06 00:00:00</th>\n      <td>1755.309692</td>\n      <td>1821.239380</td>\n      <td>1697.009644</td>\n      <td>1737.948730</td>\n      <td>9.937840e+09</td>\n    </tr>\n    <tr>\n      <th>2025-01-07 00:00:00</th>\n      <td>1763.142334</td>\n      <td>1828.231812</td>\n      <td>1700.270020</td>\n      <td>1737.885742</td>\n      <td>9.520869e+09</td>\n    </tr>\n    <tr>\n      <th>2025-01-08 00:00:00</th>\n      <td>1781.604248</td>\n      <td>1845.217529</td>\n      <td>1721.257446</td>\n      <td>1759.425293</td>\n      <td>1.039972e+10</td>\n    </tr>\n    <tr>\n      <th>2025-01-09 00:00:00</th>\n      <td>1790.498047</td>\n      <td>1851.689575</td>\n      <td>1725.914917</td>\n      <td>1763.695190</td>\n      <td>1.004115e+10</td>\n    </tr>\n  </tbody>\n</table>\n<p>2619 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_original_scale = scaler.inverse_transform(y_pred)\n",
    "\n",
    "columns = dataframe.columns\n",
    "y_pred_df = pd.DataFrame(predictions, columns=columns)\n",
    "\n",
    "last_date = dataframe.index[-1]\n",
    "\n",
    "future_dates = pd.date_range(start=last_date, periods=len(y_pred_df) + 1, freq='D')[1:]\n",
    "\n",
    "predictions_with_dates = pd.DataFrame(y_pred_original_scale, columns=columns, index=future_dates)\n",
    "\n",
    "concatenated_df = pd.concat([dataframe, predictions_with_dates])\n",
    "\n",
    "concatenated_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T14:53:48.236948700Z",
     "start_time": "2023-11-21T14:53:48.172477500Z"
    }
   },
   "id": "4a939b5bd435b02a"
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "df_plot = pd.read_csv(\"../data/processed_data/ETH/DAY/ETH_data_2023-11-21_12-14-48.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T14:53:55.566694600Z",
     "start_time": "2023-11-21T14:53:55.537483200Z"
    }
   },
   "id": "c3656c9c2f8b9eec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataframe_normalized.corr()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7c6954bbbacaf91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
